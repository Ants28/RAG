# Simple RAG pipeline

Uses LLama.cpp and docker and has a server interface so that you can interact with it.


# Running 

be in the project repo 

<docker build RAG .>

Make sure to have the llama model of choice in a /models directory in the project,
and the files you want to vectorize in a /documents directory
